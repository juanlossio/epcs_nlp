{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087e830e-7017-49c4-9261-b6ab99038df5",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing For token classification\n",
    "## for EXPOSURE events only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaeff7d-4e1f-4a31-882d-24dea599f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets import Dataset, DatasetDict, ClassLabel, Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb146cc9-c05c-4ba2-87ca-03916055e0b8",
   "metadata": {},
   "source": [
    "# 1. All data without any filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b339f39-ae57-48d1-8693-c63ff5a25ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '/home/lossioventuraj2/Code/07-Transcripts/words_w_exp_fine_V2/'\n",
    "subsets = ['2_training', '3_validation', '4_testing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e20a0-b57b-4fc8-a0cf-8b76035be601",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataframes = []\n",
    "csv_per_set = {}\n",
    "\n",
    "list_length_tokens = []\n",
    "\n",
    "for subset_ in subsets:\n",
    "    name_dataset = subset_[2:]\n",
    "    dataframes = {}\n",
    "    print(name_dataset)\n",
    "    list_files = os.listdir(path_dataset + subset_)\n",
    "    list_files.sort()\n",
    "    print(f\"\\tNumber of files: {len(list_files)}\")\n",
    "    for file_ in list_files:\n",
    "        df_aux = pd.read_csv(path_dataset + subset_ + \"/\" + file_)\n",
    "        dataframes[file_[:-16]] = df_aux  ## We have to include the exposure number\n",
    "        list_length_tokens.append(df_aux.shape[0])\n",
    "        list_dataframes.append(df_aux)\n",
    "        #print(df_aux.shape)\n",
    "\n",
    "    csv_per_set[name_dataset] = dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cea51c-8562-4442-a763-0804fbb9104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    'id': Value('string'),\n",
    "    'tokens': Value('string'),\n",
    "    'labels': ClassLabel(names=[\"NoEX\",\"EX\"])  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c13aa6-6331-41fc-ba52-8a795e52e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a554cf-338e-48c0-88bd-3f5369442c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(csv_per_set['training']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180461c4-82b2-4acc-b49a-5170abf420cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_for_Datasets = {}\n",
    "MAX_LENGTH = 256\n",
    "feature_to_study = \"exposure\"\n",
    "\n",
    "for set_, dict_of_dataframes in csv_per_set.items():\n",
    "    print(set_)\n",
    "    print(len(dict_of_dataframes))\n",
    "\n",
    "    dataset_list = []\n",
    "    for name, df in dict_of_dataframes.items():\n",
    "        #print(name)\n",
    "        tokens = df['WORD'].tolist()\n",
    "        #labels = df['DiscourageAvoidance'].tolist()\n",
    "        labels = df['Exposure'].tolist()\n",
    "    \n",
    "        #print(len(tokens))\n",
    "        for i in range(0, len(tokens), MAX_LENGTH):\n",
    "            #print(i)\n",
    "            dict_aux_ = {\n",
    "                \"ID\": str(name),\n",
    "                'SUB_ID': str(name) + f\"_part{i // MAX_LENGTH + 1}\",  # Convert ID to string\n",
    "                'tokens': [str(token) for token in tokens[i:i + MAX_LENGTH]],  # Ensure string type\n",
    "                'ner_tags': [int(label) for label in labels[i:i + MAX_LENGTH]]   # Ensure string type\n",
    "            }\n",
    "            dataset_list.append(dict_aux_)\n",
    "\n",
    "    dataset_aux = Dataset.from_list(dataset_list)\n",
    "    list_for_Datasets[set_] = dataset_aux\n",
    "\n",
    "dataset_dict = DatasetDict(list_for_Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e954d1-8595-48e6-aaee-61e1c6c49abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataset_dict))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df63f5fc-10fc-41e9-bcc6-7bc4bc1b6603",
   "metadata": {},
   "source": [
    "# Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b0ffb6-2df4-4720-9ff2-65a27a204799",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_exposure = f\"datasets/no_slide_windows/window_{MAX_LENGTH}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad437a9-41b8-4977-a7c6-4dbd0dbace29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict.save_to_disk(f\"{path_data_exposure}{feature_to_study}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b1541-dced-4c5a-95f8-840674a8201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = dataset_dict[\"training\"]\n",
    "print(type(training_dataset))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f7648-a5d9-49f2-a5fc-0e99cccf28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298c37f-2510-4d7f-9c2e-d9be5a8a8e21",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82682f6-6e3d-491c-8029-44b6e09ece10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Load the DatasetDict from the saved directory\n",
    "loaded_dataset_dict = DatasetDict.load_from_disk(f\"{path_data_exposure}{feature_to_study}\")\n",
    "\n",
    "# Now `loaded_dataset_dict` is the same as the original dataset_dict\n",
    "print(loaded_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d13b5f6-1329-4d7a-81bf-435e75900b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418a301-4ca3-4f42-940b-9297a0b5ec4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
